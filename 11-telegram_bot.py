import os
import pandas as pd
from telegram import Update
from telegram.ext import Updater, CommandHandler, CallbackContext
from pymongo import MongoClient
from datetime import datetime, timedelta

ins_codes = {
    "46348559193224090": "ÙÙˆÙ„Ø§Ø¯",
    '6110133418282108': "Ù¾Ø§Ø±Ø³",
    '35700344742885862': "Ú©Ú¯Ù„",
    '7395271748414592': "ÙˆØ®Ø§Ø±Ø²Ù…",
    '778253364357513': "ÙˆØ¨Ù…Ù„Øª",
    '2400322364771558': "Ø´Ø³ØªØ§",
    '7745894403636165': "Ø´Ù¾Ù†Ø§",
    '65883838195688438': "Ø®ÙˆØ¯Ø±Ùˆ",
    '48511238766369097': "Ø¯Ø§Ù†Ø§",
    '67988012428906654': "Ø¯Ø§Ø±Ùˆ",
    '15949743338644220': "Ø³Ø§Ø±ÙˆÙ…"
}


import joblib

mongo_client_news = MongoClient('mongodb://localhost:27017/')
db_news = mongo_client_news['telegram_data']
collection_news = db_news['messages']

mongo_client_metrics = MongoClient('mongodb://localhost:27017/')
db_metrics = mongo_client_metrics['tse']
collection_metrics = db_metrics['IsinPrices_live']
MODELS_DIR = r"D:\project\Predict_stock_price\models"


def load_model(stock_symbol):
    model_file = os.path.join(MODELS_DIR, f"{stock_symbol}.pkl")
    if not os.path.exists(model_file):
        return None
    return joblib.load(model_file)


def process_data():
    start_time = datetime.now() - timedelta(days=1)
    start_time = start_time.replace(hour=12, minute=30, second=0, microsecond=0)
    end_time = datetime.now()

    pipeline_news = [
        {
            "$match": {
                "date": {"$gte": start_time, "$lt": end_time},
                "$or": [
                    {"positive": {"$gt": 0.003}},
                    {"negative": {"$gt": 0.003}},
                    {"neutral": {"$gt": 0.98}}
                ]
            }
        },
        {
            "$group": {
                "_id": "$channel",
                "positive_sentiment_count": {"$sum": {"$cond": [{"$gt": ["$positive", 0.003]}, 1, 0]}},
                "negative_sentiment_count": {"$sum": {"$cond": [{"$gt": ["$negative", 0.003]}, 1, 0]}},
                "neutral_sentiment_count": {"$sum": {"$cond": [{"$gt": ["$neutral", 0.98]}, 1, 0]}},
                "total_messages": {"$sum": 1}
            }
        }
    ]

    news_results = list(collection_news.aggregate(pipeline_news))

    ins_codes_prediction = {}
    for ins_code in list(ins_codes.keys()):
        data = list(collection_metrics.find({"ins_code": int(ins_code)}).sort('DEven', -1))
        latest_metric = data[-1]['total_transactions']
        previous_metric = data[-2]['total_transactions']
        change_total_transactions = (latest_metric - previous_metric) / previous_metric * 100

        metrics = {
            "change_total_transactions": change_total_transactions,
            "change_volume": (data[-1]['volume'] - data[-2]['volume']) / data[-1]['volume'] * 100,
            "change_index_value": (data[-1]['index_value'] - data[-2]['index_value']) / data[-1]['index_value'] * 100
        }
        channel_mapping = {'IranintlTV': 0, 'Saberin_ir': 1, 'Tasnimnews': 2, 'akharinkhabar': 3, 'akhbarefori': 4,
                           'bbcpersian': 5, 'farsna': 6, 'irZagrosNews': 7, 'khabarfarda_ir': 8, 'tweet_Khabari': 9}
        model = load_model(ins_code)
        predictions = []
        for news in news_results:
            channel_code = channel_mapping[news["_id"]]
            test_data = pd.DataFrame({
                "positive_sentiment_count": [news['positive_sentiment_count']],
                "negative_sentiment_count": [news['negative_sentiment_count']],
                "neutral_sentiment_count": [news['neutral_sentiment_count']],
                "channel_name_encoded": [channel_code],
                "change_total_transactions": [metrics['change_total_transactions']],
                "change_volume": [metrics['change_volume']],
                "change_index_value": [metrics['change_index_value']],
            })
            predictions.append(int(model.predict(test_data)[0]))

        ins_codes_prediction.update({ins_code: (sum(predictions) / len(predictions))})

    return ins_codes_prediction


# ØªØ§Ø¨Ø¹ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±
def report(update: Update, context: CallbackContext) -> None:
    data = process_data()
    if not data:
        update.message.reply_text("âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        return

    range_res = {
        0: "ğŸ“‰ Ú©Ø§Ù‡Ø´ Ø´Ø¯ÛŒØ¯",
        1: "ğŸ“‰ Ú©Ø§Ù‡Ø´ Ø¬Ø²Ø¦ÛŒ",
        2: "âš–ï¸ Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±",
        3: "ğŸ“ˆ Ø§ÙØ²Ø§ÛŒØ´ Ø¬Ø²Ø¦ÛŒ",
        4: "ğŸ“ˆ Ø§ÙØ²Ø§ÛŒØ´ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡",
    }
    response = "ğŸ“Š **Ú¯Ø²Ø§Ø±Ø´ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ø§Ø²Ø§Ø± Ø³Ù‡Ø§Ù…**\n\n"
    for ins_code, prediction in data.items():
        stock_name = ins_codes.get(ins_code, "Ù†Ø§Ù…Ø´Ø®Øµ")
        response += f"   - {stock_name}: {range_res[int(prediction)]}\n"

    response += "\nğŸ”¹ Ø§ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ Ø³Ù‡ Ø±ÙˆØ²Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡ Ù‡Ø³ØªÙ†Ø¯."
    update.message.reply_text(response, parse_mode="Markdown")

def main():
    # ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯
    TELEGRAM_TOKEN = ''

    updater = Updater(TELEGRAM_TOKEN)
    dispatcher = updater.dispatcher

    # Ø«Ø¨Øª Ø¯Ø³ØªÙˆØ± `/report`
    dispatcher.add_handler(CommandHandler("report", report))

    updater.start_polling()
    updater.idle()


if __name__ == '__main__':
    main()
